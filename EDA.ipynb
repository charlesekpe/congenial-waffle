{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>queue</th>\n",
       "      <th>priority</th>\n",
       "      <th>language</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>subject</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCOUNTING</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>EN</td>\n",
       "      <td>Customer Inquiries::Payments</td>\n",
       "      <td>Inquiry About Payment Method Update</td>\n",
       "      <td>Dear Support Team,\\n\\nI would like to update t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCOUNTING</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>DE</td>\n",
       "      <td>Employee Inquiries::Health and Safety</td>\n",
       "      <td>Mängel Gesundheitsbericht Anwendung</td>\n",
       "      <td>Sehr geehrtes Support-Team, ich nutze Ihre Anw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOFTWARE</td>\n",
       "      <td>LOW</td>\n",
       "      <td>EN</td>\n",
       "      <td>Crypto Wallets</td>\n",
       "      <td>Crypto Wallets Update Inquiry and Billing Info</td>\n",
       "      <td>Good day, I hope everything is great on your e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCOUNTING</td>\n",
       "      <td>LOW</td>\n",
       "      <td>EN</td>\n",
       "      <td>Employee Inquiries::Staff Development</td>\n",
       "      <td>Possibility of Business Name Change on Next In...</td>\n",
       "      <td>Hello team,\\n\\nI noticed there's a slight typo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HARDWARE</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>EN</td>\n",
       "      <td>Temperature Sensor</td>\n",
       "      <td>High Priority: Temperature Sensor Not Powering Up</td>\n",
       "      <td>I urgently need assistance with my hardware te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        queue priority language                            subcategory  \\\n",
       "0  ACCOUNTING   MEDIUM       EN           Customer Inquiries::Payments   \n",
       "1  ACCOUNTING   MEDIUM       DE  Employee Inquiries::Health and Safety   \n",
       "2    SOFTWARE      LOW       EN                         Crypto Wallets   \n",
       "3  ACCOUNTING      LOW       EN  Employee Inquiries::Staff Development   \n",
       "4    HARDWARE     HIGH       EN                     Temperature Sensor   \n",
       "\n",
       "                                             subject  \\\n",
       "0                Inquiry About Payment Method Update   \n",
       "1                Mängel Gesundheitsbericht Anwendung   \n",
       "2     Crypto Wallets Update Inquiry and Billing Info   \n",
       "3  Possibility of Business Name Change on Next In...   \n",
       "4  High Priority: Temperature Sensor Not Powering Up   \n",
       "\n",
       "                                                text  \n",
       "0  Dear Support Team,\\n\\nI would like to update t...  \n",
       "1  Sehr geehrtes Support-Team, ich nutze Ihre Anw...  \n",
       "2  Good day, I hope everything is great on your e...  \n",
       "3  Hello team,\\n\\nI noticed there's a slight typo...  \n",
       "4  I urgently need assistance with my hardware te...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ticket-helpdesk-multi-lang.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 399 entries, 0 to 398\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   queue        399 non-null    object\n",
      " 1   priority     399 non-null    object\n",
      " 2   language     399 non-null    object\n",
      " 3   subcategory  399 non-null    object\n",
      " 4   subject      399 non-null    object\n",
      " 5   text         399 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 18.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check for null values and incorrect data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in queue: ['ACCOUNTING' 'SOFTWARE' 'HARDWARE']\n",
      "| queue      | count   |\n",
      "|:-----------|:--------|\n",
      "| SOFTWARE   | 226     |\n",
      "| ACCOUNTING | 91      |\n",
      "| HARDWARE   | 82      |\n"
     ]
    }
   ],
   "source": [
    "# Explore the queue column\n",
    "print(f\"Unique values in queue: {df['queue'].unique()}\")\n",
    "\n",
    "print(df['queue'].value_counts().to_markdown(numalign=\"left\", stralign=\"left\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Dear Support Team,\\n\\nI would like to update t...\n",
       "1    Sehr geehrtes Support-Team, ich nutze Ihre Anw...\n",
       "2    Good day, I hope everything is great on your e...\n",
       "3    Hello team,\\n\\nI noticed there's a slight typo...\n",
       "4    I urgently need assistance with my hardware te...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore the text column\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Support Team,\n",
      "\n",
      "I would like to update the payment method linked to my account. I recently encountered an issue with my current payment method and would prefer to switch to a different one. Additionally, I have an outstanding invoice for which I need an updated version reflecting the new payment details.\n",
      "\n",
      "Thank you for your prompt assistance.\n",
      "\n",
      "Best regards,\n",
      "Anthony Weber, Cust# 53212\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert texts to lower case\n",
    "\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ea28157bf4b1443eb4902dbeb3d1c508.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ea28157bf4b1443eb4902dbeb3d1c508.vega-embed details,\n",
       "  #altair-viz-ea28157bf4b1443eb4902dbeb3d1c508.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ea28157bf4b1443eb4902dbeb3d1c508\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ea28157bf4b1443eb4902dbeb3d1c508\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ea28157bf4b1443eb4902dbeb3d1c508\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0a51f4443c9b44a93a3311e60f3fce2f\"}, \"mark\": {\"type\": \"bar\"}, \"encoding\": {\"tooltip\": [{\"field\": \"Language\", \"type\": \"nominal\"}, {\"field\": \"Frequency\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"labelAngle\": -45}, \"field\": \"Language\", \"type\": \"nominal\"}, \"y\": {\"field\": \"Frequency\", \"type\": \"quantitative\"}}, \"params\": [{\"name\": \"param_3\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\"}], \"title\": \"Distribution of Languages\", \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.17.0.json\", \"datasets\": {\"data-0a51f4443c9b44a93a3311e60f3fce2f\": [{\"Language\": \"EN\", \"Frequency\": 173}, {\"Language\": \"DE\", \"Frequency\": 89}, {\"Language\": \"ES\", \"Frequency\": 89}, {\"Language\": \"FR\", \"Frequency\": 48}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect the disttribution of languages\n",
    "language_counts = df['language'].value_counts().reset_index()\n",
    "language_counts.columns = ['Language', 'Frequency']\n",
    "\n",
    "chart = alt.Chart(language_counts).mark_bar().encode(\n",
    "    x=alt.X('Language', axis=alt.Axis(labelAngle=-45)),\n",
    "    y=alt.Y('Frequency:Q'),\n",
    "    tooltip=['Language', 'Frequency']\n",
    ").properties(\n",
    "    title='Distribution of Languages'\n",
    ").interactive()\n",
    "\n",
    "chart.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model into path\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cwchang/text-classification-model-multilingual\", cache_dir='.')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cwchang/text-classification-model-multilingual\", cache_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUILD THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at models--cwchang--text-classification-model-multilingual/snapshots/939b37821955f4846485f16ac4b18c962b2edc42 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([150]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([150, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"models--cwchang--text-classification-model-multilingual/snapshots/939b37821955f4846485f16ac4b18c962b2edc42\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"models--cwchang--text-classification-model-multilingual/snapshots/939b37821955f4846485f16ac4b18c962b2edc42\",\n",
    "                                                           num_labels=df['queue'].nunique(),\n",
    "                                                           ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib # for saving the `queue` encoder\n",
    "import torch\n",
    "\n",
    "# Encode the `queue` column\n",
    "label_encoder = LabelEncoder()\n",
    "df['queue_encoded'] = label_encoder.fit_transform(df['queue'])\n",
    "\n",
    "# Save the label encoder\n",
    "joblib.dump(label_encoder, 'queue_encoder.joblib')\n",
    "\n",
    "# Split the dataset\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].tolist(),\n",
    "    df['queue_encoded'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Tokenize the text\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "\n",
    "# Create a dataset object\n",
    "class TicketDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = TicketDataset(train_encodings, train_labels)\n",
    "val_dataset = TicketDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([177])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/miniforge3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  The optimizer for which to schedule the learning rate.\n",
      "Training Epoch 1: 100%|██████████| 20/20 [02:48<00:00,  8.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.0605864554643631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 5/5 [00:02<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9663825988769531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 20/20 [02:03<00:00,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.843424865603447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 5/5 [00:01<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9905829071998596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 20/20 [02:17<00:00,  6.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5938209861516952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 5/5 [00:01<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.9304910182952881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Set up the dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=f'Training Epoch {epoch + 1}'):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Train loss: {train_loss / len(train_loader)}')\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "    print(f'Validation loss: {val_loss / len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ACCOUNTING'], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./results/tokenizer_config.json',\n",
       " './results/special_tokens_map.json',\n",
       " './results/vocab.txt',\n",
       " './results/added_tokens.json',\n",
       " './results/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./results')\n",
    "tokenizer.save_pretrained('./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./results')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('./results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
